from typing import Dict, Any, List
# Import Modules
from services.product_agent.retriever import get_retriever
from services.crm_agent.generator import get_generator
from services.crm_agent.intent_parser import get_intent_parser
from services.crm_agent.data_loader import get_data_loader

class Orchestrator:
    def __init__(self):
        self.retriever = get_retriever()
        self.generator = get_generator()
        self.parser = get_intent_parser()
        
    def process_query_stream(self, user_text: str, history: List[Dict[str, str]] = []):
        """
        Streaming Pipeline (Generator)
        Yields dicts: {"type": "status"|"data", ...}
        """
        
        # 1. Parse Intent
        yield {"type": "status", "msg": "ê³ ê°ë‹˜ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ê³  ìˆì–´ìš”... ğŸ§"}
        parsed = self.parser.parse_query(user_text)
        yield {"type": "data", "key": "parsed", "value": parsed}
        
        extracted = parsed["extracted"]
        product_query = extracted.get("product")
        target_persona = parsed["candidates"]["persona"][0] if parsed["candidates"]["persona"] else "Unknown"
        target_purpose = parsed["candidates"]["purpose"][0] if parsed["candidates"]["purpose"] else "Unknown"
        
        # 2. Retrieve Products (Model-1)
        yield {"type": "status", "msg": "ì í•©í•œ ìƒí’ˆê³¼ í˜œíƒì„ ì°¾ê³  ìˆì–´ìš”... ğŸ“¦"}
        
        # Use extracted product query or fallback to full text
        search_q = product_query if product_query else user_text
        product_cands = self.retriever.retrieve(search_q)
        
        # Serialize product candidates for UI
        serialized_products = []
        for p in product_cands[:3]: # Top 3
            serialized_products.append({
                "name": p.product_name,
                "brand": p.brand,
                "score": p.score,
                "claims": p.factsheet.voice_info.key_claims
            })
            
        # Send candidates data immediately
        candidates_data = {
            "products": serialized_products,
            "personas": parsed["candidates"]["persona"],
            "purposes": parsed["candidates"]["purpose"],
            "detected_brand": "Unknown", # Will update
            "brand_tone": "Default"      # Will update
        }
        
        # 3. Generate Message (Model-2)
        yield {"type": "status", "msg": "ë§¤ë ¥ì ì¸ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ê³  ìˆì–´ìš”... âœï¸"}
        
        brand_tone_info = {}
        if product_cands:
            top_product = product_cands[0]
            # Fetch Brand Tone
            brand_tone_info = self.retriever.loader.get_brand_tone(top_product.brand) if hasattr(self.retriever, 'loader') else get_data_loader().get_brand_tone(top_product.brand)
            
            # Update candidates with brand info and send
            candidates_data["detected_brand"] = brand_tone_info.get("brand_name", top_product.brand)
            candidates_data["brand_tone"] = brand_tone_info.get("tone_voice", "Default")
            yield {"type": "data", "key": "candidates", "value": candidates_data}
            
            # Initial Generation
            msg = self.generator.generate_response(
                product_cand=top_product,
                persona_name=target_persona,
                action_purpose=target_purpose,
                channel="ë¬¸ì(LMS)", # Default
                history=history # Pass History
            )
            
            # -----------------------------------------------------------------
            # FEEDBACK LOOP (Regulation Check)
            # -----------------------------------------------------------------
            yield {"type": "status", "msg": "ê·œì œ ìœ„ë°˜ ì—¬ë¶€ë¥¼ ê¼¼ê¼¼íˆ ì ê²€ ì¤‘ì´ì—ìš”... ğŸ‘®"}
            
            audit_trail = []
            final_msg = msg
            
            # Import Regulation Agent lazily
            from services.regulation_agent.compliance import get_compliance_agent
            reg_agent = get_compliance_agent()
            
            max_retries = 3
            chk_result = None
            
            for attempt in range(max_retries + 1): # 0 to 3
                # Check Compliance
                chk_result = reg_agent.check_compliance(final_msg)
                
                # Record Audit
                audit_entry = {
                    "attempt": attempt + 1,
                    "message": final_msg,
                    "status": chk_result["status"],
                    "feedback": chk_result["feedback"]
                }
                audit_trail.append(audit_entry)
                
                if chk_result["status"] == "PASS":
                    break
                
                # If FAIL, refine (unless it's the last attempt)
                if attempt < max_retries:
                    yield {"type": "status", "msg": f"ê·œì œ ìœ„ë°˜ ë°œê²¬! ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤... ({attempt+1}/{max_retries}) ğŸ”§"}
                    
                    print(f"[Orchestrator] Attempt {attempt+1} Failed. Refining...")
                    final_msg = self.generator.refine_response(
                        original_msg=final_msg,
                        feedback=chk_result["feedback"],
                        feedback_detail=f"Please fix the violations: {chk_result['feedback']}"
                    )
            
            # Final Result
            yield {"type": "data", "key": "final_message", "value": final_msg}
            yield {"type": "data", "key": "audit_trail", "value": audit_trail}
            
            # -----------------------------------------------------------------
            # DYNAMIC SUGGESTIONS (Post-Generation)
            # -----------------------------------------------------------------
            yield {"type": "status", "msg": "ì¶”ê°€ ì œì•ˆì„ ìƒê°í•˜ê³  ìˆì–´ìš”... ğŸ’¡"}
            print("[Orchestrator] Calling generate_suggestions...")
            suggestions = self.generator.generate_suggestions(
                original_msg=final_msg,
                product_name=top_product.product_name,
                target_persona=target_persona
            )
            print(f"[Orchestrator] Yielding suggestions: {suggestions}")
            yield {"type": "data", "key": "suggestions", "value": suggestions}
            
            yield {"type": "data", "key": "suggestions", "value": suggestions}
            
        else:
            # 2-B. Fallback: General Conversation Mode
            # Instead of "Sorry", generate a natural response
            yield {"type": "status", "msg": "ğŸ’¬ ë‹µë³€ì„ ìƒê°í•˜ê³  ìˆì–´ìš”..."}
            
            candidates_data["detected_brand"] = None
            candidates_data["brand_tone"] = None
            yield {"type": "data", "key": "candidates", "value": candidates_data}
            
            # Generate General Response
            gen_response = self.generator.generate_general_chat(user_text)
            
            yield {"type": "data", "key": "final_message", "value": gen_response}
            yield {"type": "data", "key": "audit_trail", "value": []}
            
            # Fallback suggestions for general chat
            yield {"type": "data", "key": "suggestions", "value": ["ì„¤í™”ìˆ˜ ì‹ ì œí’ˆ ë³´ì—¬ì¤˜", "ë§ˆì¼€íŒ… ë¬¸êµ¬ ì¶”ì²œí•´ì¤˜", "ë¼ë„¤ì¦ˆ ì´ë²¤íŠ¸ ì•Œë ¤ì¤˜"]}
            
        yield {"type": "status", "msg": "ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! âœ¨"}

_orch_instance = None
def get_orchestrator():
    global _orch_instance
    if _orch_instance is None:
        _orch_instance = Orchestrator()
    return _orch_instance
