{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Compliance Agent (CRM Validator) - **Double-Check Logic**\n",
                "\n",
                "This agent validates CRM messages against two regulations:\n",
                "1. **Spam Regulation** (`불법스팸_방지_안내서_임베딩.json`)\n",
                "2. **Cosmetics Regulation** (`화장품_지침_임베딩.json`)\n",
                "\n",
                "**Logic**:\n",
                "- **Retrieval**: Query Expansion (True RAG).\n",
                "- **Double-Check**: Validation runs twice. If EITHER run fails, the final verdict is FAIL. This minimizes false positives (unsafe passes)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: openai in c:\\users\\junsang\\anaconda3\\lib\\site-packages (2.14.0)\n",
                        "Requirement already satisfied: numpy in c:\\users\\junsang\\anaconda3\\lib\\site-packages (1.26.4)\n",
                        "Requirement already satisfied: scikit-learn in c:\\users\\junsang\\anaconda3\\lib\\site-packages (1.7.2)\n",
                        "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
                        "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
                        "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
                        "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from openai) (0.12.0)\n",
                        "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from openai) (2.12.5)\n",
                        "Requirement already satisfied: sniffio in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
                        "Requirement already satisfied: tqdm>4 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
                        "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from openai) (4.14.1)\n",
                        "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
                        "Requirement already satisfied: idna>=2.8 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
                        "Requirement already satisfied: certifi in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
                        "Requirement already satisfied: httpcore==1.* in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
                        "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
                        "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
                        "Requirement already satisfied: colorama in c:\\users\\junsang\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
                    ]
                }
            ],
            "source": [
                "!pip install openai numpy scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import getpass\n",
                "import numpy as np\n",
                "from openai import OpenAI\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "\n",
                "# 1. Setup OpenAI\n",
                "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
                "if not api_key:\n",
                "    api_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
                "\n",
                "client = OpenAI(api_key=api_key)\n",
                "\n",
                "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
                "    text = text.replace(\"\\n\", \" \")\n",
                "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded Spam DB: 40 chunks\n",
                        "Loaded Cosmetics DB: 9 chunks\n"
                    ]
                }
            ],
            "source": [
                "# 2. Load Vector Databases\n",
                "spam_db_path = \"불법스팸_방지_안내서_임베딩.json\"\n",
                "cosmetics_db_path = \"화장품_지침_임베딩.json\"\n",
                "\n",
                "def load_db(path):\n",
                "    if not os.path.exists(path):\n",
                "        print(f\"Warning: {path} not found.\")\n",
                "        return []\n",
                "    with open(path, 'r', encoding='utf-8') as f:\n",
                "        return json.load(f)\n",
                "\n",
                "spam_db = load_db(spam_db_path)\n",
                "cosmetics_db = load_db(cosmetics_db_path)\n",
                "\n",
                "print(f\"Loaded Spam DB: {len(spam_db)} chunks\")\n",
                "print(f\"Loaded Cosmetics DB: {len(cosmetics_db)} chunks\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. True RAG Retrieval Logic (Deep Retrieval with Query Expansion)\n",
                "def retrieve_top_k(query_embedding, db, k=5):\n",
                "    if not db:\n",
                "        return []\n",
                "    \n",
                "    db_embeddings = [item['embedding'] for item in db]\n",
                "    similarities = cosine_similarity([query_embedding], db_embeddings)[0]\n",
                "    \n",
                "    # Get top-k indices\n",
                "    top_indices = similarities.argsort()[-k:][::-1]\n",
                "    \n",
                "    results = []\n",
                "    for idx in top_indices:\n",
                "        results.append({\n",
                "            \"score\": similarities[idx],\n",
                "            \"metadata\": db[idx]['metadata']\n",
                "        })\n",
                "    return results\n",
                "\n",
                "def generate_legal_queries(crm_message):\n",
                "    \"\"\"\n",
                "    Smart Query Generation.\n",
                "    \"\"\"\n",
                "    prompt = f\"\"\"\n",
                "    Analyze the CRM message and generate 3 specific legal search queries.\n",
                "    Goal: Retrieve rules that apply to SMS/LMS, but ALSO common rules for all advertising media (e.g., Article 50).\n",
                "    \n",
                "    CRM Message:\n",
                "    {crm_message}\n",
                "    \n",
                "    Generate concise queries for:\n",
                "    1. SMS-specific marking requirements (Opt-out, Sender ID).\n",
                "    2. Common advertising prohibitions (False/Exaggerated claims, common to all media).\n",
                "    3. Product-specific restrictions (e.g., Cosmetics medical claims).\n",
                "    \n",
                "    Output List only.\n",
                "    \"\"\"\n",
                "    \n",
                "    response = client.chat.completions.create(\n",
                "        model=\"gpt-4o\",\n",
                "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                "        temperature=0\n",
                "    )\n",
                "    \n",
                "    queries = response.choices[0].message.content.strip().split(\"\\n\")\n",
                "    return [q.split(\". \")[-1] for q in queries if q.strip()]\n",
                "\n",
                "def get_combined_context(message):\n",
                "    # 1. Query Expansion\n",
                "    search_queries = generate_legal_queries(message)\n",
                "    print(f\"Generated Search Queries: {search_queries}\")\n",
                "    \n",
                "    all_spam_docs = []\n",
                "    all_cosmetics_docs = []\n",
                "    \n",
                "    # 2. Retrieve for EACH query\n",
                "    for q in search_queries:\n",
                "        q_vec = get_embedding(q)\n",
                "        all_spam_docs.extend(retrieve_top_k(q_vec, spam_db, k=3))\n",
                "        all_cosmetics_docs.extend(retrieve_top_k(q_vec, cosmetics_db, k=3))\n",
                "        \n",
                "    # Also retrieve for original message\n",
                "    original_vec = get_embedding(message)\n",
                "    all_spam_docs.extend(retrieve_top_k(original_vec, spam_db, k=3))\n",
                "    all_cosmetics_docs.extend(retrieve_top_k(original_vec, cosmetics_db, k=3))\n",
                "    \n",
                "    # 3. Deduplicate\n",
                "    def deduplicate(docs):\n",
                "        unique_docs = []\n",
                "        seen_headers = set()\n",
                "        for doc in docs:\n",
                "            key = doc['metadata']['header'] + doc['metadata']['content'][:30]\n",
                "            if key not in seen_headers:\n",
                "                unique_docs.append(doc)\n",
                "                seen_headers.add(key)\n",
                "        return unique_docs\n",
                "\n",
                "    final_spam_docs = deduplicate(all_spam_docs)\n",
                "    final_cosmetics_docs = deduplicate(all_cosmetics_docs)\n",
                "    \n",
                "    context_text = f\"-- [Regulation 1: Spam Prevention & IT Network Act (Total {len(final_spam_docs)})] --\\n\"\n",
                "    for doc in final_spam_docs:\n",
                "        context_text += f\"Header: {doc['metadata']['header']}\\nContent: {doc['metadata']['content']}\\n\\n\"\n",
                "        \n",
                "    context_text += f\"\\n-- [Regulation 2: Cosmetics Guidelines (Total {len(final_cosmetics_docs)})] --\\n\"\n",
                "    for doc in final_cosmetics_docs:\n",
                "        context_text += f\"Header: {doc['metadata']['header']}\\nContent: {doc['metadata']['content']}\\n\\n\"\n",
                "        \n",
                "    return context_text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Compliance Check Function (Double-Check Logic)\n",
                "def _run_single_check(crm_message, run_id):\n",
                "    \"\"\"Internal function for a single pass\"\"\"\n",
                "    print(f\"  > Run {run_id}: Generating queries and validating...\")\n",
                "    \n",
                "    # 1. Retrieve Context\n",
                "    context = get_combined_context(crm_message)\n",
                "    \n",
                "    # 2. Construct Prompt\n",
                "    system_prompt = \"\"\"\n",
                "    당신은 한국 기업의 엄격한 컴플라이언스(규제 준수) 담당자입니다.\n",
                "    입력된 메시지는 **휴대폰 문자 메시지(SMS/LMS)**입니다.\n",
                "    \n",
                "    [규정 적용 원칙 - 중요]\n",
                "    1. 매체 특수성: 문자 메시지 특유의 규칙은 최우선 적용하십시오.\n",
                "        - 주의: 이메일 전용(제목란 등)이나 팩스 전용 규칙은 배제하십시오.\n",
                "    2. 공통 규정 적용: 정보통신망법 제50조 등 \"영리목적 광고성 정보 전송 시 공통 준수사항\"은 매체와 무관하게 적용되므로 놓치지 마십시오.\n",
                "       - 예: '전송자의 명칭 및 연락처 표시', '수신거부 비용 무료' 등은 공통사항입니다.\n",
                "    \n",
                "    [심사 Process]\n",
                "    1. [Context Regulations]에서 SMS에 적용 가능한 조항과, 모든 매체에 적용되는 공통 조항을 식별하십시오.\n",
                "    2. [CRM Message]가 해당 조항들을 문자 그대로 준수하는지 대조하십시오.\n",
                "    \n",
                "    [출력 양식]\n",
                "    Case 1: 위반 사항 발견 (FAIL)\n",
                "    - 판정: [실패]\n",
                "    - 근거 규정: [Context 조항 명] (예: 정보통신망법 제50조 제4항)\n",
                "    - 위반 설명: [구체적 내용]\n",
                "    - 수정 제안 (Before -> After):\n",
                "      1. [현재] -> [수정]\n",
                "    \n",
                "    Case 2: 문제 없음 (PASS)\n",
                "    - 판정: [통과]\n",
                "    - 심사 내용: [Context]의 공통 규정(명칭, 연락처, 무료수신거부) 및 SMS 특화 규정((광고)위치) 준수 확인됨.\n",
                "    \"\"\"\n",
                "    \n",
                "    user_prompt = f\"\"\"\n",
                "    Context Regulations (Source of Truth):\n",
                "    {context}\n",
                "    \n",
                "    CRM Message (SMS/LMS):\n",
                "    {crm_message}\n",
                "    \n",
                "    Check for violations significantly strictly based on Context.\n",
                "    \"\"\"\n",
                "    \n",
                "    response = client.chat.completions.create(\n",
                "        model=\"gpt-4o\",\n",
                "        messages=[\n",
                "            {\"role\": \"system\", \"content\": system_prompt},\n",
                "            {\"role\": \"user\", \"content\": user_prompt}\n",
                "        ],\n",
                "        temperature=0\n",
                "    )\n",
                "    return response.choices[0].message.content\n",
                "\n",
                "def check_compliance(crm_message):\n",
                "    print(\"Analyzing message with Dual-Pass Logic (2 checks for safety)...\\n\")\n",
                "    \n",
                "    # Run 1\n",
                "    result1 = _run_single_check(crm_message, 1)\n",
                "    \n",
                "    # Run 2\n",
                "    result2 = _run_single_check(crm_message, 2)\n",
                "    \n",
                "    # Conservatism Rule: If ANY run fails, the final verdict is FAIL.\n",
                "    if \"[실패]\" in result1:\n",
                "        print(\"\\n[Final Verdict]: FAIL (Detected in Run 1)\")\n",
                "        return result1\n",
                "    elif \"[실패]\" in result2:\n",
                "        print(\"\\n[Final Verdict]: FAIL (Detected in Run 2 - Run 1 missed it)\")\n",
                "        return result2\n",
                "    else:\n",
                "        print(\"\\n[Final Verdict]: PASS (Both runs confirmed safety)\")\n",
                "        return result1 # Doesn't matter which one, both are Pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Message ---\n",
                        "Analyzing message with Dual-Pass Logic (2 checks for safety)...\n",
                        "\n",
                        "  > Run 1: Generating queries and validating...\n",
                        "Generated Search Queries: ['SMS-specific marking requirements for opt-out and sender ID in advertising.', 'Common advertising prohibitions against false or exaggerated claims applicable to all media.', 'Product-specific advertising restrictions for cosmetics, including medical claims limitations.']\n",
                        "  > Run 2: Generating queries and validating...\n",
                        "Generated Search Queries: ['\"SMS marketing legal requirements opt-out sender ID South Korea\"', '\"Common advertising prohibitions false exaggerated claims South Korea\"', '\"Product-specific advertising restrictions cosmetics medical claims South Korea\"']\n",
                        "\n",
                        "[Final Verdict]: PASS (Both runs confirmed safety)\n",
                        "- 판정: [통과]\n",
                        "- 심사 내용: [Context]의 공통 규정(명칭, 연락처, 무료수신거부) 및 SMS 특화 규정((광고)위치) 준수 확인됨.\n"
                    ]
                }
            ],
            "source": [
                "# 5. Run Test Cases\n",
                "message = \"\"\"\n",
                "(광고) [삼성물산] 주말 특가 안내 - 삼성물산 : 02-123-4567\n",
                "고객님, 이번 주말 전 품목 20% 할인 행사를 진행합니다.\n",
                "무료수신거부 080-1234-5678\n",
                "\"\"\"\n",
                "\n",
                "\n",
                "\n",
                "print(\"--- Message ---\")\n",
                "print(check_compliance(message))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
